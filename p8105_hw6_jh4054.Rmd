---
title: "p8105_hw6_jh4054"
author: "Joy Hsu"
date: "11/24/2018"
output: 
    html_document:
      toc: true
      toc_float: true
      code_folding: show
---

```{r setup, include=FALSE}
library(tidyverse)
library(knitr)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  collapse = TRUE)

set.seed(1)

theme_set(theme_bw() + theme(legend.position = "bottom"))
```

### Problem 1

The raw homicide dataset was collated by Washington Post on 52179 homicide cases in 50 major US cities, from 2007 to 2015. Altogether, 28 states are represented. The raw dimensions are 52179 rows by 12 columns variables. Each case is reported as a distinct row, with demographic information on the victim's name, age, sex, and race. Attributes regarding the homicide incident include geospatial coordinates, reported date, city, and disposition of the police case. 
```{r}
#examine raw dataset
raw_dataset = read_csv("./data/homicide-data.csv")
dim(raw_dataset)

#represented states and cities
raw_dataset %>% 
  distinct(state) %>% 
  nrow()

raw_dataset %>% 
  distinct(city) %>% 
  nrow()
```

We will investigate the odds ratio of solving a homicide for white versus non-white victims. First, we tidy the dataset with the following steps:

* create city_state variable
* omit observations from "Dallas, TX", "Phoenix, AZ", "Kansas City, MO", these locations omit victim race. Omit "Tulsa, AL", erroneous entry. 
* modify victim age to numeric variable
* modify victim_race to two factor variable: white (reference) and non_white
* modify victim_sex to factor variable: Male, Female, Unknown
* create binary variable indicating whether homicide is solved: 0 = unsolved, 1 = solved. 

```{r}
#load and tidy dataset
homicide_data = read_csv("./data/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    victim_age = as.numeric(as.factor(victim_age)),
    victim_race = ifelse(victim_race == "White", "white", "non_white"),
    victim_race = fct_relevel(victim_race, c("white", "non_white")),
    victim_sex = as.factor(victim_sex),
    hom_unsolved = as.factor(ifelse(disposition != "Closed by arrest", 0, 1))) %>% 
  filter(!(city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO")))

str(homicide_data)
```

#### Baltimore, MD

For the city of Baltimore, MD, we fit a logistic regression with resolved versus unresolved homicide as the outcome and victim age, sex, and race (white vs. non-white) as predictors. The odds of solving a homicide case for a non-white victim in Baltimore, MD is on average 0.452 (95% CI: 0.321, 0.636) times the odds for a white homicide victim, keeping all other variables constant.

```{r}
# filter dataframe for baltimore victims only
baltimore_df = homicide_data %>% 
   filter(city_state == "Baltimore, MD") 

# glm for baltimore unsolved homicides
glm_baltimore = baltimore_df %>%
  glm(hom_unsolved ~ victim_age + victim_race + victim_sex, family = binomial(), data = .)

# table for adjusted odds ratio, 95% Confidence Interval, p-value 
glm_baltimore %>% broom::tidy(conf.int = TRUE, exponentiate = TRUE) %>% 
  select(term, estimate, conf.low, conf.high, p.value) %>% 
  rename(
    "OR" = estimate, 
    "95% CI lower" = conf.low, 
    "95% CI upper" = conf.high) %>% 
  filter(term == "victim_racenon_white") %>% 
  knitr::kable(digits = 3)
```

#### All Cities

The Odds Ratio and 95% Confidence Interval for solving a homicide case for a non-white victim versus a white victim is reported for 47 major US cities.

```{r, fig.width = 10, fig.height = 6}
# Odds Ratio for victim_racenon_white in 47 cities
logfit_cities = homicide_data %>% 
  select(city_state, hom_unsolved, victim_age, victim_race, victim_sex) %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(
    logfit = map(data, ~glm(hom_unsolved ~ victim_age + victim_race + victim_sex, family = binomial(), data = .)),
    logfit = map(logfit, ~broom::tidy(., conf.int = TRUE, exponentiate = TRUE))) %>% 
  select(city_state, logfit) %>% 
  unnest() %>% 
  filter(term == "victim_racenon_white") %>% 
  select(city_state, estimate, conf.low, conf.high, p.value) %>% 
  rename(
    "OR" = estimate, 
    "CI_lower" = conf.low, 
    "CI_upper" = conf.high) %>% 
  mutate(city_state = fct_reorder(city_state, OR))

# OR and 95% CI for each city
logfit_cities %>% 
  arrange(OR) %>% 
  knitr::kable(digits = 3)

# plot
OR_plot = logfit_cities %>% 
  ggplot(aes(x = city_state, y = OR, color = city_state)) +
  geom_point() +
  geom_errorbar(mapping = aes(x = city_state, ymin = CI_lower, ymax = CI_upper)) + 
  labs(
    title = "Odds Ratio of Solving Homicide Case, Race non-white vs. white",
    x = "City",
    y = "Odds Ratio",
    caption = "*Case Data collated by Washington Post") + 
  viridis::scale_color_viridis(
    name = "City, State", 
    discrete = TRUE) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), 
        legend.position = "bottom")
OR_plot
```

### Problem 2.1 - Propose Model

In this section, we will investigate the birthweight dataset and propose a regression model for birthweight. 

We will start our approach to model building by exploring the distribution of the main response. Next, we will select 2 model candidates from 1) stepwise backwards elimination and 2) optimization of the adjusted R~2~ criteria. Candidates will be assessed for linear regression model assumptions, normality of the residuals and homoscadescity of residuals. Lastly, candidates will be compared for parsimony and assessed for multicollinearity. 

###### **Data Cleaning**

Data Cleaning Steps

* exclude following two variables with values "0" for all observations.  
    * pnumlbw: previous number of low birth weight babies
    * pnumgsa: number of prior small for gestational age babies
* convert baby sex, father race, mother race, and malformations to factor variables

```{r}
# load birthweight dataset
bw = read_csv("./data/birthweight.csv")

# tidy dataset
bw = bw %>% 
  mutate(
    babysex = as.factor(recode(babysex, "1" = "male", "2" = "female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8), labels = c("white", "black", "asian", "puerto_rican", "other")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4), labels = c("white", "black", "asian", "puerto_rican")),
    malform = factor(malform, levels = c(0, 1), labels = c("absent", "present"))) %>% 
  select(-pnumlbw, -pnumsga)
```

###### **Birthweight Histogram**

Distribution of the main response birthweight approximates a normal distribution.

```{r}
bw %>% 
  ggplot(aes(x = bwt)) +
  geom_histogram()
```

###### **Stepwise Backward Elimation**

Using an automatic search function that minimizes AIC using stepwise backward elimination, we obtain model candidate 1:

Step:  AIC=48705.38
bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken

```{r}
library(leaps)

# Specify full and null models for forward & backward selection based on AIC Criteria
null = lm(bwt ~ 1, data = bw)
null

full = lm(bwt ~ ., data = bw)
full

# perform stepwise backward selection
step(full, data = bw, direction="backward")
```

###### **regsubsets()** - regression subset selection

The all possible regressions approach considers all possible subsets of the pool of explanatory variables and finds the model that best fits the data according to some criteria (e.g. Adjusted R~2~ and BIC). These criteria assign scores to each model and allow us to choose the model with the best score.

* The model containing explanatory variables bhead, blength, delwt, frace:puerto_rican, gaweeks, mraceblack, ppbmi, and smoken optimizes the **adjusted R~2~ criteria** and minimizes the **BIC criteria**. 
* The top 5 models in the R~2~(adj) plot have roughly the same R~2~(adj). Since there is marginal improvement in the R~2~(adj) score by including frace:puerto_rican, we will exclude father race (frace) from the candidate model. 
* Since we must include all factors within a variable, we will retain mother race (mrace). 

From this exploration, we obtain model candidtate 2: 

bwt ~ bhead + blength + delwt + gaweeks + mrace + ppbmi + smoken

```{r}
leaps = leaps::regsubsets(bwt ~ ., data = bw)
# View the ranked models according to the adjusted r-squared criteria and BIC, respectively
# black indicates that a variable is included in the model, white not included. 
plot(leaps, scale = "adjr2")
plot(leaps, scale = "bic")

fit2 = lm(bwt ~ bhead + blength + delwt + gaweeks + mrace + ppbmi + smoken, data = bw)
summary(fit2)
```

###### Check Model Diagnostics for 2 Candidate Models

**Candidate Models:**

1. Stepwise Backward Elimination:
bwt ~ bhead + blength + mrace + delwt + gaweeks + smoken + ppbmi + babysex + parity + ppwt + fincome

2. Optimize adjusted R~2~ criteria:
bwt ~ bhead + blength + delwt + gaweeks + mrace + ppbmi + smoken 

For both models, we add residuals and predictions to the birthweight data

```{r}
# Candidate 1: Stepwise Backward Elimination Model, 11 predictors
fit_step = lm(bwt ~ bhead + blength + mrace + delwt + gaweeks + smoken + ppbmi + babysex + parity + ppwt + fincome, data = bw)
summary(fit_step)

# add predictions and residuals to stepwise model
bw_fit_step = modelr::add_predictions(bw, fit_step, var = "pred_step")
bw_fit_step = modelr::add_residuals(bw_fit_step, fit_step, var = "resid_step")

# Candidate 2: adjusted R-square Model, 7 predictors
fit_rs = lm(bwt ~ bhead + blength + delwt + gaweeks + mrace + ppbmi + smoken, data = bw)
summary(fit_rs)

# add predictions and residuals to adjusted r-square model
bw_fit_rs = modelr::add_predictions(bw, fit_rs, var = "pred_rs")
bw_fit_rs = modelr::add_residuals(bw_fit_rs, fit_rs, var = "resid_rs")
```

**1. Normality of Residuals (error distribution)**

1. Assess for nearly normal residuals with mean 0
    * on a residuals plot, we look for random scatter of residuals around 0, this translates to a nearly normal distribution of residuals centered at 0
    * check using histogram of residuals and normal probability plot

Both candidate models have acceptible normality per Q-Q Plot and Histogram of Residuals

**1a) Stepwise Model QQ-Plot & Histogram**
```{r}
# evaluate normality of residuals with qq plot
qqnorm(fit_step$residuals)
qqline(fit_step$residuals)

# evaluate normality of residuals with histogram
hist(fit_step$residuals)
```

**1b) R-Square Model QQ-Plot & Histogram**
```{r}
# evaluate normality of residuals with qq plot
qqnorm(fit_rs$residuals)
qqline(fit_rs$residuals)

# evaluate normality of residuals with histogram
hist(fit_rs$residuals)
```

**2. Homoscedasticity: Constant variance of residuals (errors)**

2. Assess for constant variability of residuals 
    * check using residuals plots of residuals vs. predicted value (e vs. y_hat)
        * residuals should be equally variable for low and high values of the predicted response variable
        * residuals randomly scattered in a band with a constant width around 0 (no fan shaped)
        
Both candidate models have reasonable homoscedasticity for birthweight values between 1500 to 4500 grams. The model does not do a great job at predicting birthweights at the lower end of the distribution, ~ below 1500 grams. 
```{r}
# Stepwise Model: predicted value vs. residuals plot
bw_fit_step %>% 
  ggplot(aes(x = pred_step, y = resid_step)) +
  geom_point(alpha = 0.3)

# R-square Model: predicted value vs. residuals plot
bw_fit_rs %>% 
  ggplot(aes(x = pred_rs, y = resid_rs)) +
  geom_point(alpha = 0.3)
```

###### Optimize Parsimony and Assess Multicollinearity

Both the backwards elimination model and adjusted r-squared model satisfied assumptions for 1) normality of residuals and 2) constant variance of residuals (between birthweights 1500-4500gram)

Optimizing for parsimony, we will select the R~2~(adj) model with 7 predictors over the backwards elimination model with 11 predictors. 

7 Predictor Model: bwt ~ bhead + blength + delwt + gaweeks + mrace + ppbmi + smoken 

Lastly, we will check for multicollinearity in the 7 predictor model using a 1) correlation matrix and 2) VIF (variance inflation factor) Scores, which measure how much of the variance of a regression coefficient is inflated due to multicollinearity within the model). We will drop variable pre-pregnancy BMI due to the high correlation coefficient (0.72) with variable delivery weight.

```{r}
# check for collinearity between numerical predictor variables
bw_fit_rs %>% 
  select(bwt, bhead, blength, delwt, gaweeks, ppbmi, smoken) %>% 
  GGally::ggpairs()

# Evaluate VIF Scores
car::vif(fit_rs)
```

###### Final Proposed Model

Dropping pre-pregnancy bmi only marginally decreases the R~2~(adj), from 0.716 to 0.713. The final proposed 6 predictor model satisfies regression assumptions for 1) normality of residuals and 2) constant variance of residuals

bwt ~ bhead + blength + delwt + gaweeks + mrace + smoken

```{r}
# Final Model
fit_final = lm(bwt ~ bhead + blength + delwt + gaweeks + mrace + smoken, data = bw)
summary(fit_final) %>% broom::tidy() %>% knitr::kable()
summary(fit_final) %>% broom::glance() %>% knitr::kable()


# Prediction vs Residuals Plot
bw_fit_final = modelr::add_predictions(bw, fit_final, var = "pred")
bw_fit_final = modelr::add_residuals(bw_fit_final, fit_final, var = "resid")

bw_fit_final %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3)

# histogram of residuals
bw_fit_final %>% 
  ggplot(aes(x = resid)) +
    geom_histogram()
```

### Problem 2.2 Cross-Validation, Compare Models

We will use cross validation to compare the final proposed model (fit_final) with a two predictor model (blength, gaweeks) and three-way interaction model (bhead, blength, babysex). 

Iteration for RMSE will be performed over 100 cross validation sets with a 80% training and 20% test split.

```{r}
# two predictor model
fit_2 = lm(bwt ~ blength, gaweeks, data = bw)
summary(fit_2)

# 3 way interaction model
fit_3 = lm(bwt ~ bhead * blength * babysex, data = bw)
summary(fit_3)
```

```{r}
cv_bw = modelr::crossv_mc(data = bw, n = 100, test = 0.2, id = "id")

cv_bw = cv_bw %>% 
  mutate(lm_final = map(train, ~lm(bwt ~ bhead + blength + delwt + gaweeks + mrace + smoken, data = .x)),
         lm_2pred = map(train, ~lm(bwt ~ blength, gaweeks, data = .x)),
         lm_3pred = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))) %>% 
  mutate(rmse_final = map2_dbl(lm_final, test, ~rmse(model = .x, data = .y)),
         rmse_2pred = map2_dbl(lm_2pred, test, ~rmse(model = .x, data = .y)),
         rmse_3pred = map2_dbl(lm_3pred, test, ~rmse(model = .x, data = .y)))
```

Violin Plot of RMSE

Proposed model has the lowest range of RMSE
```{r}
cv_bw %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(
    model = str_replace(model, "rmse_", "model "),
    model = fct_reorder(model, rmse)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
    geom_violin() +
  labs(title = "Distribution of RMSE, Violin Plots", 
    x = "Model", 
    y = "RMSE")
```

